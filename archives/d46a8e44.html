<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.2.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico"><link rel="mask-icon" href="/images/favicon.ico" color="#222"><meta name="google-site-verification" content="35AYyqm-wpmGmXtkn-vQMrk7AkFl1Do55uHdlLLLT38"><meta name="baidu-site-verification" content="slBbq5f8WxljPytW"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="//fonts.proxy.ustclug.org/css?family=Lato:300,300italic,400,400italic,700,700italic&amp;display=swap&amp;subset=latin,latin-ext"><link rel="stylesheet" href="//lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/5.15.4/css/all.min.css"><link rel="stylesheet" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//unpkg.com/pace-js@1/themes/blue/pace-theme-minimal.css"><script src="//unpkg.com/pace-js@1.2.4/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"yousazoe.top",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:"mac"},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:!0,pangu:!0,comments:{style:"tabs",active:null,storage:!0,lazyload:!0,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:3,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="引言本文翻译自 光綫追蹤降噪技術，概述光线追踪降噪方法，包含滤波、时空、采样和人工智能技术，以改进光追应用的收敛性和时间一致性。"><meta property="og:type" content="article"><meta property="og:title" content="光线追踪降噪技术"><meta property="og:url" content="https://yousazoe.top/archives/d46a8e44.html"><meta property="og:site_name" content="Fl0w3r"><meta property="og:description" content="引言本文翻译自 光綫追蹤降噪技術，概述光线追踪降噪方法，包含滤波、时空、采样和人工智能技术，以改进光追应用的收敛性和时间一致性。"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-65dfa4c995e1178f4c536581ad8c1387_r.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-12cf2336a8111fc4f202ae43cf38e1b9_720w.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-a797bee5f0d5bdfab39cf76a2dbd7ba4_720w.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-8b3c4b3713e0e54d059e26b57ae050fc_720w.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-3f5adce9843abb99417da69c3ef072ff_720w.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-99dbb3ccd2f6e5c21c5b6ad1f65dbcb8_720w.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-a5bc9c71b618fc8d3135afe24be8d931_720w.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-68d8a6656b6ce2480c8852fc3dcaf46c_720w-20210914150330062.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-f45cb15cfd005fe56d9fecad9200d3f6_720w.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-ec8baa43fd74d6936fd118cf52319a63_r.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-6a824e3850cb8ce8f6ab941015f56ed3_720w.jpg"><meta property="article:published_time" content="2021-09-14T06:49:18.000Z"><meta property="article:modified_time" content="2022-11-01T16:01:26.633Z"><meta property="article:author" content="Yousazoe"><meta property="article:tag" content="Computer Graphics"><meta property="article:tag" content="Ray Tracing"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-65dfa4c995e1178f4c536581ad8c1387_r.jpg"><link rel="canonical" href="https://yousazoe.top/archives/d46a8e44.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"en"}</script><title>光线追踪降噪技术 | Fl0w3r</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="Fl0w3r" type="application/atom+xml"></head><body itemscope="" itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="Toggle navigation bar"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">Fl0w3r</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">carpe diem</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-address-card fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-links"><a href="/links/" rel="section"><i class="fa fa-paperclip fa-fw"></i>Links</a></li><li class="menu-item menu-item-photos"><a href="/photos/" rel="section"><i class="fa fa-camera fa-fw"></i>Photos</a></li><li class="menu-item menu-item-artitalk"><a href="/artitalk/" rel="section"><i class="fa fa-calendar fa-fw"></i>Artitalk</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-document"><a href="/docs/" rel="section"><i class="fas fa-book fa-fw"></i>Document</a></li><li class="menu-item menu-item-qexoadmin"><a href="https://blog-yousazoe-qexo.vercel.app/" rel="noopener" target="_blank"><i class="fa fa-database fa-fw"></i>QexoAdmin</a></li><li class="menu-item menu-item-gametracker"><a href="https://yousazoe.notion.site/yousazoe/b05999823bd14b57a7a6cd81fba1a1af?v=21c3398e0bdb429c9b8157b7bf12ff6a" rel="noopener" target="_blank"><i class="fas fa-trophy fa-fw"></i>GameTracker</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="Searching..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="reading-progress-bar"></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope="" itemtype="http://schema.org/Article" class="post-block" lang="en"><link itemprop="mainEntityOfPage" href="https://yousazoe.top/archives/d46a8e44.html"><span hidden="" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="image" content="https://img.yousazoe.top/uPic/img/blog/icon/icon.jpeg"><meta itemprop="name" content="Yousazoe"><meta itemprop="description" content="done is better than perfect"></span><span hidden="" itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="Fl0w3r"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">光线追踪降噪技术</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Created: 2021-09-14 14:49:18" itemprop="dateCreated datePublished" datetime="2021-09-14T14:49:18+08:00">2021-09-14</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">In</span> <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA-Ray-Tracing/" itemprop="url" rel="index"><span itemprop="name">光线追踪 (Ray Tracing)</span></a> </span></span><span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Views: </span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="Symbols count in article"><span class="post-meta-item-icon"><i class="fas fa-pen"></i></span><span>13k</span> </span><span class="post-meta-item" title="Reading time"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span>24 mins.</span></span></div></header><div class="post-body" itemprop="articleBody"><p><img data-src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-65dfa4c995e1178f4c536581ad8c1387_r.jpg"></p><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>本文翻译自 <a target="_blank" rel="noopener" href="https://www.yuque.com/isumiai/cg/efwkig">光綫追蹤降噪技術</a>，概述光线追踪降噪方法，包含滤波、时空、采样和人工智能技术，以改进光追应用的收敛性和时间一致性。</p><span id="more"></span><p>蒙特卡洛光线追踪是一种基于随机样本的累积来近似给定场景的方法，一般来说该方法是缓慢的，但随着基于最新图形卡的实时光线追踪解决方案的出现，在去噪技术上的研究有了复苏。</p><p>这些去噪技术包括使用导向模糊内核的<strong>滤波</strong>技术；<strong>机器学习</strong>驱动的滤波器或重要性采样；通过更好的拟随机序列如蓝色噪音，以及时空累积的采样方案来改进<strong>采样</strong>；尝试用某种空间结构(如探针probes、辐照度缓存irradiance caches等)量化结果的 <strong>近似</strong>技术</p><p>根据应用程序的权衡和需要，一个鲁棒的去噪器应该考虑使用<strong>所有</strong>这些技术。</p><p>最近的研究集中在通过改进采样方案和用缓存的信息重采样像素，将降噪步骤移动到渲染早期。之前的研究集中在滤波、机器学习中的自动编码器、重要性采样和实时方法上。这些方法目前用于各种商业游戏和渲染器中。本文将讨论降噪及其实现的关键论文，重点在如何实现自己的鲁棒实时光线追踪降噪方法。</p><h3 id="Prior-Art"><a href="#Prior-Art" class="headerlink" title="Prior Art"></a>Prior Art</h3><p><img data-src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-12cf2336a8111fc4f202ae43cf38e1b9_720w.jpg"></p><p>使用高斯 Gaussian、双边 Bilateral、多孔 A-Trous [Dammertz et al. 2010]、导向 Guided [He et al. 2012] 和中值 Median [Mara et al. 2017] 等<strong>滤波技术</strong>对蒙特卡洛光线追踪图像进行模糊处理。特别是由特征缓冲区 feature buffers（如延迟渲染中的 common G-Buffer 附件：法线，反射率，深度/位置；以及特殊的缓冲区：首次反弹数据 first-bounce data，重投影路径长度 reprojected path length，或观察位置 view position）驱动的导向滤波器，已经在最近的论文和商业实现中使用。</p><p>虽然这些滤波技术是有效的且计算量小，但代价是有损的场景表示和高频信息如锐利边缘的损失。这种信息丢失非常严重，甚至会导致在处理带有椒盐噪声的高光或阴影图案中产生亮度水平上的差异。</p><p><img data-src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-a797bee5f0d5bdfab39cf76a2dbd7ba4_720w.jpg"></p><p><strong>机器学习</strong>已经被广泛用于与降噪相关的领域，从一般的图像重建到通过使用降噪自编码器实现的实时光线追踪去噪[Khademi Kalantari et al. 2013] [Khademi Kalantari et al. 2015] [R. Alla Chaitanya et al. 2017] [Vogels et al. 2018]，导向滤波技术[Wang et al. 2018] [Xu et al. 2019] [Meng et al. 2020]，时空技术[Hasselgren et al. 2020]，以及通过超分辨率/超采样来提高图像的分辨率，同时保持细节的方法 [Dong et al. 2015] [Ledig et al. 2016] [Xiao et al. 2020]。</p><p>Intel 和 NVIDIA 等行业领军企业支持了基于机器学习的去噪方法的研究，Intel Open Image Denoise 和 NVIDIA Optix Autoencoder 都使用自动编码器去噪，取得了巨大成功。NVIDIA 的深度学习超采样 (DLSS 2.0) 也被用于光追游戏中，如 Minecraft RTX，Control 等，通过深度学习提高分辨率来降低计算成本。</p><p><img data-src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-8b3c4b3713e0e54d059e26b57ae050fc_720w.jpg"></p><p><strong>采样</strong>技术在最新的论文中再度兴起。虽然 naive 版本的蒙特卡洛光线追踪只是简单地在一个不变的场景上累加样本，但是在一个移动的场景中重用样本是可能的。包括 TAA Temporal Anti-Aliasing [Korein et al. 1983] [Yang et al. 2020]，时空滤波器 Spatio-Temporal Filter [Mara et al. 2017，时空方差引导滤波器 Spatio-Temporal Variance Guided Filter (SVGF) [Schied 2017]，空间去噪Spatial Denoising [Abdollah-shamshir-saz 2018]，自适应 SVGF (A-SVGF) [Schied 2018], 分开多阶特征回归 Blockwise Multi-Order Feature Regression (BMFR) [Koskela et al. 2019]</p><p>这些技术依赖于高频准随机序列 quasi-random sequences，如蓝噪声(与滤波结合使用)[Benyoub 2019]，以及常见的工具，如 firefly rejection[Liu et al. 2019]、下一事件估计 next event estimation(NEE) 和重要性采样 importance sampling [Veach 1998]</p><p>最近，有人尝试通过 ray hashing [Pantaleoni 2020] 来减少采样的偏差或重用邻近采样数据[Bitterli et al. 2020]，将降噪转移到渲染更早期的阶段中。</p><p><img data-src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-3f5adce9843abb99417da69c3ef072ff_720w.jpg"></p><p>此外，还有 <strong>近似</strong>技术，试图微调路径追踪器的各个方面。RTX Global Illumination 论文使用光探针 light probes 模拟全局光照，使用光线追踪来更好地确定每个探针的辐射度，并将探针定位在场景中，以避免 bleeding 或内部错误。RTXGI 最近被集成到商业游戏引擎中，如 Unreal Engine 4 和 Unity [Majercik et al. 2020]</p><h3 id="Sampling"><a href="#Sampling" class="headerlink" title="Sampling"></a>Sampling</h3><h4 id="SVGF"><a href="#SVGF" class="headerlink" title="SVGF"></a>SVGF</h4><p>时空方差导向滤波 Spatio-Temporal Variance Guided Filter SVGF [Schied 2017]是一种使用时空重投影和特征缓冲驱动的双边滤波来模糊高方差区域的去噪方法。</p><p>Minecraft RTX 使用了 SVGF，并添加了辐照度 irradiance 缓存 ，使用光线长度来更好地驱动反射，以及对透光表面 (如水) 的分割渲染。SVGF 虽然非常有效，但在游戏中产生了明显的延迟。</p><h4 id="A-SVGF"><a href="#A-SVGF" class="headerlink" title="A-SVGF"></a>A-SVGF</h4><p>自适应时空方差导向滤波 Adaptive spatial - temporal Variance Guided Filtering, a -SVGF [Schied 2018] 改进了 SVGF，自适应的将之前的样本根据时间特征（如方差、视角等的变化）在空间上进行重新投影，在 Moment Buffer 中编码，并通过快速双边滤波器进行滤波。因此，与基于历史长度累积样本不同，采用方差的变化来决定旧样本和新样本的比例，从而减少重影 ghosting。SVGF 只使用 moment buffer 来做模糊，而 A-SVGF 则是既进行滤波有进行累积。</p><p>虽然引入一个 moment buffer 有助于消除时间延迟，但并不能完全消除它。积累样本较多的区域和新区域之间可能存在亮度差异。这在较暗的光线追踪场景，如室内尤为明显。为了缓解这个问题，与其使用 1 spp，最好在教案的区域使用 2 spp。</p><p>Quake 2 RTX 使用 A-SVGF 作为去噪解决方案。</p><h4 id="ReSTIR"><a href="#ReSTIR" class="headerlink" title="ReSTIR"></a>ReSTIR</h4><p>多光源光线追踪的时空重要性重采样 Spatiotemporal Importance Resampling for Many-Light Ray Tracing (ReSTIR) [Bitterli et al. 2020] 试图在渲染时将实时去噪器的时空重投影步骤提前，重用邻近采样概率的统计信息。本质上是对早期论文的结合，讨论了重采样的重要性采样 Resampled Importance Sampling，并加入了时空去噪的思想。</p><p>ReSTIR 将用于 NVIDIA 的 RTXDI SDK中。</p><h3 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a>Machine Learning</h3><p>机器学习技术，如降噪自动编码器，样本图估计器驱动的样本计数或重要采样，神经双边网格滤波，超采样，虽然这些技术比其他算法如 A-SVGF 要慢，但在图像质量方面的改善最为显著。</p><h4 id="OIDN"><a href="#OIDN" class="headerlink" title="OIDN"></a>OIDN</h4><p><img data-src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-99dbb3ccd2f6e5c21c5b6ad1f65dbcb8_720w.jpg"></p><p>一个机器学习自动编码器，输入反射率 albedo，首次反弹法线，和你的输入噪声图像，输出滤波后的图像。</p><figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">// 👋 Declare Handles</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Images loaded from stb as 3 components</span></span><br><span class="line"><span class="type">float</span>* color;</span><br><span class="line"><span class="type">float</span>* normal;</span><br><span class="line"><span class="type">float</span>&amp; output;</span><br><span class="line"><span class="type">unsigned</span> width;</span><br><span class="line"><span class="type">unsigned</span> height;</span><br><span class="line"></span><br><span class="line">oidn::DeviceRef device = oidn::<span class="built_in">newDevice</span>();</span><br><span class="line">device.<span class="built_in">commit</span>();</span><br><span class="line">oidn::FilterRef filter = device.<span class="built_in">newFilter</span>(<span class="string">"RT"</span>);</span><br><span class="line">filter.<span class="built_in">setImage</span>(<span class="string">"color"</span>, color, oidn::Format::Float3, width, height);</span><br><span class="line">filter.<span class="built_in">setImage</span>(<span class="string">"normal"</span>, normal, oidn::Format::Float3, width, height);</span><br><span class="line">filter.<span class="built_in">setImage</span>(<span class="string">"output"</span>, output, oidn::Format::Float3, width, height);</span><br><span class="line">filter.<span class="built_in">set</span>(<span class="string">"hdr"</span>, <span class="literal">true</span>);</span><br><span class="line">filter.<span class="built_in">commit</span>();</span><br><span class="line">filter.<span class="built_in">execute</span>();</span><br></pre></td></tr></tbody></table></figure><h4 id="Optix"><a href="#Optix" class="headerlink" title="Optix"></a>Optix</h4><p><img data-src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-a5bc9c71b618fc8d3135afe24be8d931_720w.jpg"></p><p>NVIDIA 的 Optix 7 Denoising Autoencoder [R. Alla Chaitanya et al. 2017] 采用与 OIDN 相同的输入和输出，速度比 Intel 的解决方案快得多，但以质量要差一些。</p><figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">// 👋 Declare Handles</span></span><br><span class="line">OptixContext ctx;</span><br><span class="line">OptixDevice device;</span><br><span class="line"><span class="type">unsigned</span> width;</span><br><span class="line"><span class="type">unsigned</span> height;</span><br><span class="line">CUDABuffer denoiserState;</span><br><span class="line">CUDABuffer denoiserScratch;</span><br><span class="line"></span><br><span class="line"><span class="comment">// https://github.com/ingowald/optix7course/blob/master/example12_denoiseSeparateChannels/SampleRenderer.cpp#L764</span></span><br><span class="line">OptixDenoiser denoiser;</span><br><span class="line">OptixDenoiserOptions opt;</span><br><span class="line">opt.inputKind = OPTIX_DENOISER_INPUT_RGB_ALBEDO;</span><br><span class="line">opt.pixelFormat = OPTIX_PIXEL_FORMAT_FLOAT4;</span><br><span class="line"><span class="built_in">optixDenoiserCreate</span>(ctx, &amp;opt, &amp;denoiser);</span><br><span class="line"><span class="built_in">optixDenoiserSetModel</span>(denoiser, OPTIX_DENOISER_MODEL_KIND_HDR, <span class="literal">nullptr</span>, <span class="number">0</span>);</span><br><span class="line">OptixDenoiserSizes denoiserReturnSizes;</span><br><span class="line"><span class="built_in">optixDenoiserComputeMemoryResources</span>(denoiser, width, height, &amp;denoiserReturnSizes);</span><br><span class="line">denoiserState.<span class="built_in">resize</span>(denoiserReturnSizes.stateSizeInBytes);</span><br><span class="line"><span class="built_in">optixDenoiserSetup</span>(denoiser,<span class="number">0</span>,</span><br><span class="line">                width, height,</span><br><span class="line">                denoiserState.<span class="built_in">d_pointer</span>(),</span><br><span class="line">                denoiserState.<span class="built_in">size</span>(),</span><br><span class="line">                denoiserScratch.<span class="built_in">d_pointer</span>(),</span><br><span class="line">                denoiserScratch.<span class="built_in">size</span>());</span><br></pre></td></tr></tbody></table></figure><h4 id="DLSS"><a href="#DLSS" class="headerlink" title="DLSS"></a>DLSS</h4><p>深度学习超级采样(DLSS)是一种上采样技术，它使用一个小的颜色缓冲区和一个方向图来将输出的分辨率增至 2-4 倍。这是 NVIDIA 授权的开发者独有的，目前还没有办法公开使用，不过还有其他的选择，比如 <a href="https://link.zhihu.com/?target=https://github.com/microsoft/DirectML/tree/master/Samples/DirectMLSuperResolution/Samples/ML/DirectMLSuperResolution">DirectML’s SuperResolution Sample</a>。</p><h3 id="Denoiser-Design"><a href="#Denoiser-Design" class="headerlink" title="Denoiser Design"></a>Denoiser Design</h3><p><img data-src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-68d8a6656b6ce2480c8852fc3dcaf46c_720w-20210914150330062.jpg"></p><p>一个理想的降噪器，结合了最新的技术论文的想法，可以是这样的：</p><ol><li>Prepass - 计算场景的 NDC 空间速度，编写 common G-buffer attachment 如反射率，法线等。您可能还需要 first bounce 资料作为基于光线追踪的前置。</li><li>Ray Trace - 使用带有 sample map 的 AI Adaptive sampling [Hasselgren et al. 2020]，以更好地确定哪些区域应该接收更多样本，一般是高光/阴影区域，以避免椒盐噪声，并能随着时间的推移保持亮度。将镜面反射和全局光照分别写入单独的附件的分离降噪器将是理想的，因为第一次反射的数据能更好的处理反射噪声，全局光照/环境光遮挡/阴影则可以使用更简单的时空积累。</li><li>Accumulation - 尽可能多地使用时空重投影，这对于全局光照/环境光遮挡这样的 lambertian data 来说比较容易，而对于像镜面反射这样的specular data 则比较困难。为了获得更好的结果，可以使用像normals/albedo/object IDs 这样的启发式数据来将以前的样本转换到当前位置，以及第一次反弹数据，如视图方向、第一次反弹法线/反照率等。任何成功的重投影都可以用于 importance sample [Bitterli et al. 2020] 或将其radiance 编码到 radiance 历史缓冲区中 [Schied 2018]</li><li>Statistical Analysis 统计分析 - 估计当前光线追踪图像的方差，计算亮度/速度的方差变化，并使用它来驱动时空重投影和滤波。并用方差信息拒绝 fireflies</li><li>Filtering 滤波 - 可以用一个 À-Trous bilateral filter 快速完成，根据你想要的模糊程度，重复这一步 3-5 次，每次将<code>stepWidth</code>减小 2 的幂次 (所以3次迭代的序列是4,2,1)。或者，你可以使用去噪自动编码器，它慢一些，但是可以产生更好的过滤结果。然后，这个结果可以被输入一个超级采样自动编码器，这个编码器可以提升你的结果，类似于 NVIDIA 的 DLSS 2.0</li><li>History Blit - 写入当前的数据，如反射率，深度等，以便 reprojection 下一帧</li></ol><h4 id="Prepass"><a href="#Prepass" class="headerlink" title="Prepass"></a>Prepass</h4><p>在去噪之前，重要的是使用某种 General Pass (G-Pass) 对材质信息进行编码，如法线、反射率、深度/位置、对象ID、粗糙度/金属度等。此外，速度 Velocity 信息可以将以前的样本转换到当前位置。</p><p>速度缓冲区 Velocity Buffer 可以通过顶点过去和当前的 NDC 空间坐标位置的差获得。</p><p><img data-src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-f45cb15cfd005fe56d9fecad9200d3f6_720w.jpg"></p><figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">// GLSL</span></span><br><span class="line"><span class="comment">// 🏃 NDC space velocity</span></span><br><span class="line">vec3 ndc = inPosition.xyz / inPosition.w;</span><br><span class="line">vec3 ndcPrev = inPositionPrev.xyz / inPositionPrev.w;</span><br><span class="line">outVelocity = ndc.xy - ndcPrev.xy;</span><br></pre></td></tr></tbody></table></figure><h4 id="Accumulation"><a href="#Accumulation" class="headerlink" title="Accumulation"></a>Accumulation</h4><p><img data-src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-ec8baa43fd74d6936fd118cf52319a63_r.jpg"></p><p>时空重投影 Spatiotemporal reprojection 是将以前帧中的数据空间上重新投影到当前帧中。将以前的示例转换到当前帧需要您首先在视图空间中找到前一帧数据的坐标，这可以通过速度缓冲来完成。通过比较这个屏幕空间的 当前位置/法线/对象ID等 与它之前的坐标之间的差异，可以知道一个对象是否曾经被遮挡但现在在视图中，或者重用之前的样本。</p><p>在执行时空重投影时，使用一个缓冲区来描述给定样本必须积累的时间是非常有价值的，即历史缓冲区 History Buffer。它可以用来驱动滤波器模糊在样本积累较少的区域，或者用来估计当前图像的方差(历史越长，方差越小)。</p><figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line">outHistoryLength = successfulReprojection ? prevHistoryLength + <span class="number">1.0</span> : <span class="number">0.0</span>;</span><br></pre></td></tr></tbody></table></figure><h4 id="Statistical-Analysis"><a href="#Statistical-Analysis" class="headerlink" title="Statistical Analysis"></a>Statistical Analysis</h4><figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">float</span> radius = <span class="number">2</span>; <span class="comment">//5x5 kernel</span></span><br><span class="line">vec2 sigmaVariancePair = <span class="built_in">vec2</span>(<span class="number">0.0</span>, <span class="number">0.0</span>);</span><br><span class="line"><span class="type">float</span> sampCount = <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> y = -radius; y &lt;= radius; ++y)</span><br><span class="line">{</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> x = -radius; x &lt;= radius; ++x)</span><br><span class="line">    {</span><br><span class="line">        <span class="comment">// ⬇️ Sample current point data with current uv</span></span><br><span class="line">        ivec2 p = ipos + <span class="built_in">ivec2</span>(xx, yy);</span><br><span class="line">        vec4 curColor = <span class="built_in">texelFetch</span>(tColor, p, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 💡 Determine the average brightness of this sample</span></span><br><span class="line">        <span class="comment">// 🌎 Using International Telecommunications Union's ITU BT.601 encoding params</span></span><br><span class="line">        <span class="type">float</span> samp = <span class="built_in">luminance</span>(curColor);</span><br><span class="line">        <span class="type">float</span> sampSquared = samp * samp;</span><br><span class="line">        sigmaVariancePair += <span class="built_in">vec2</span>(samp, sampSquared);</span><br><span class="line"></span><br><span class="line">        sampCount += <span class="number">1.0</span>;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line">sigmaVariancePair /= sampCount;</span><br><span class="line"><span class="type">float</span> variance = <span class="built_in">max</span>(<span class="number">0.0</span>, sigmaVariancePair.y - sigmaVariancePair.x * sigmaVariancePair.x);</span><br></pre></td></tr></tbody></table></figure><p>Christoph Schied 在 A-SVGF 中使用 edge avoiding guassian filter 的组合进行空间方差估计，并在一个 feedback 循环中使用它来驱动时空重投影期间的 <code>accumulationFactor</code>。</p><figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Variance Estimation</span></span><br><span class="line"><span class="comment"> * Copyright (c) 2018, Christoph Schied</span></span><br><span class="line"><span class="comment"> * All rights reserved.</span></span><br><span class="line"><span class="comment"> * 🎓 Slightly simplified for this example:</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ⛏️ Setup</span></span><br><span class="line"><span class="type">float</span> weightSum = <span class="number">1.0</span>;</span><br><span class="line"><span class="type">int</span> radius = <span class="number">3</span>; <span class="comment">// ⚪ 7x7 Gaussian Kernel</span></span><br><span class="line">vec2 moment = <span class="built_in">texelFetch</span>(tMomentPrev, ipos, <span class="number">0</span>).rg;</span><br><span class="line">vec4 c = <span class="built_in">texelFetch</span>(tColor, ipos, <span class="number">0</span>);</span><br><span class="line"><span class="type">float</span> histlen = <span class="built_in">texelFetch</span>(tHistoryLength, ipos, <span class="number">0</span>).r;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> yy = -radius; yy &lt;= radius; ++yy)</span><br><span class="line">{</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> xx = -radius; xx &lt;= radius; ++xx)</span><br><span class="line">    {</span><br><span class="line">        <span class="comment">// ☝️ We already have the center data</span></span><br><span class="line">        <span class="keyword">if</span> (xx != <span class="number">0</span> &amp;&amp; yy != <span class="number">0</span>) { <span class="keyword">continue</span>; }</span><br><span class="line"></span><br><span class="line">        <span class="comment">// ⬇️ Sample current point data with current uv</span></span><br><span class="line">        ivec2 p = ipos + <span class="built_in">ivec2</span>(xx, yy);</span><br><span class="line">        vec4 curColor = <span class="built_in">texelFetch</span>(tColor, p, <span class="number">0</span>);</span><br><span class="line">        <span class="type">float</span> curDepth = <span class="built_in">texelFetch</span>(tDepth, p, <span class="number">0</span>).x;</span><br><span class="line">        vec3 curNormal = <span class="built_in">texelFetch</span>(tNormal, p, <span class="number">0</span>).xyz;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 💡 Determine the average brightness of this sample</span></span><br><span class="line">        <span class="comment">// 🌎 Using International Telecommunications Union's ITU BT.601 encoding params</span></span><br><span class="line">        <span class="type">float</span> l = <span class="built_in">luminance</span>(curColor.rgb);</span><br><span class="line"></span><br><span class="line">        <span class="type">float</span> weightDepth = <span class="built_in">abs</span>(curDepth - depth.x) / (depth.y * <span class="built_in">length</span>(<span class="built_in">vec2</span>(xx, yy)) + <span class="number">1.0e-2</span>);</span><br><span class="line">        <span class="type">float</span> weightNormal = <span class="built_in">pow</span>(<span class="built_in">max</span>(<span class="number">0</span>, <span class="built_in">dot</span>(curNormal, normal)), <span class="number">128.0</span>);</span><br><span class="line"></span><br><span class="line">        uint curMeshID =  <span class="built_in">floatBitsToUint</span>(<span class="built_in">texelFetch</span>(tMeshID, p, <span class="number">0</span>).r);</span><br><span class="line"></span><br><span class="line">        <span class="type">float</span> w = <span class="built_in">exp</span>(-weightDepth) * weightNormal * (meshID == curMeshID ? <span class="number">1.0</span> : <span class="number">0.0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">isnan</span>(w))</span><br><span class="line">            w = <span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line">        weightSum += w;</span><br><span class="line"></span><br><span class="line">        moment += <span class="built_in">vec2</span>(l, l * l) * w;</span><br><span class="line">        c.rgb += curColor.rgb * w;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">moment /= weightSum;</span><br><span class="line">c.rgb /= weightSum;</span><br><span class="line"></span><br><span class="line">varianceSpatial = (<span class="number">1.0</span> + <span class="number">2.0</span> * (<span class="number">1.0</span> - histlen)) * <span class="built_in">max</span>(<span class="number">0.0</span>, moment.y - moment.x * moment.x);</span><br><span class="line">outFragColor = <span class="built_in">vec4</span>(c.rgb, (<span class="number">1.0</span> + <span class="number">3.0</span> * (<span class="number">1.0</span> - histlen)) * <span class="built_in">max</span>(<span class="number">0.0</span>, moment.y - moment.x * moment.x));</span><br></pre></td></tr></tbody></table></figure><p>Firefly Rejection 可以通过多种方式实现，从调整光线追踪期间的采样方式，到使用滤波技术或启发式方法来调整输出亮度。</p><p><strong>Increase Roughness Per Bounce</strong></p><figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">//https://twitter.com/YuriyODonnell/status/1199253959086612480</span></span><br><span class="line"><span class="comment">//http://cg.ivd.kit.edu/publications/p2013/PSR_Kaplanyan_2013/PSR_Kaplanyan_2013.pdf</span></span><br><span class="line"><span class="comment">//http://jcgt.org/published/0007/04/01/paper.pdf</span></span><br><span class="line"><span class="type">float</span> oldRoughness = payload.roughness;</span><br><span class="line">payload.roughness = <span class="built_in">min</span>(<span class="number">1.0</span>, payload.roughness + roughnessBias);</span><br><span class="line">roughnessBias += oldRoughness * <span class="number">0.75f</span>;</span><br></pre></td></tr></tbody></table></figure><p><strong>Clamp Rejection</strong></p><figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">// 🗜️ Ray Tracing Gems Chapter 17</span></span><br><span class="line"><span class="function">vec3 <span class="title">fireflyRejectionClamp</span><span class="params">(vec3 radiance, vec3 maxRadiance)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">min</span>(radiance, maxRadiance);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p><strong>Variance Rejection</strong></p><figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">// 🧯 Ray Tracing Gems Chapter 25</span></span><br><span class="line"><span class="function">vec3 <span class="title">fireflyRejectionVariance</span><span class="params">(vec3 radiance, vec3 variance, vec3 shortMean, vec3 dev)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    vec3 dev = <span class="built_in">sqrt</span>(<span class="built_in">max</span>(<span class="number">1.0e-5</span>, variance));</span><br><span class="line">    vec3 highThreshold = <span class="number">0.1</span> + shortMean + dev * <span class="number">8.0</span>;</span><br><span class="line">    vec3 overflow = <span class="built_in">max</span>(<span class="number">0.0</span>, radiance - highThreshold);</span><br><span class="line">    <span class="keyword">return</span> radiance - overflow;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h4 id="Filtering"><a href="#Filtering" class="headerlink" title="Filtering"></a>Filtering</h4><p>A-Trous 避免了以轻微抖动的模式进行采样，以覆盖比通常 3x3 或 5x5 高斯核更大的范围，能够重复多次，并避免了由于不同输入的数量而在边缘产生的模糊。</p><p>可以与下列工作结合进行:</p><ul><li>根据抖动模式进行子采样，从而进一步减少了模糊内核中的样本数量</li><li>用更多的信息来驱动你的模糊操作，比如表面粗糙度 [Abdollah-shamshir-saz 2018]，the aproximate Specular BRDF lobe [Tokuyoshi 2015]，shadow penumbras [Liu et al. 2019], etc.</li></ul><h4 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h4><p>所有这些算法都依赖于重用数据，因此当不可能重用数据时，比如在快速移动的对象、高度复杂的几何图形或历史信息很少的区域，这些方法的质量都会下降。有一些方法可以利用一些缓存数据来帮助避免这种情况，比如在 Minecraft RTX 中使用 irradiance 缓存来获得更好的默认颜色。</p><p><img data-src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="https://cdn.jsdelivr.net/gh/Yousazoe/picgo-repo/img/v2-6a824e3850cb8ce8f6ab941015f56ed3_720w.jpg"></p><p>时空重投影在处理反射时也非常困难，所以通常降噪器将依赖第一次反射的数据，其中反射表面的法线和位置数据等都是基于第一次反射的。</p><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ul><li><p><a target="_blank" rel="noopener" href="https://jo.dreggn.org/home/2010_atrous.pdf">[Dammertz et al. 2010] <strong>Edge-Avoiding À-Trous Wavelet Transform for fast Global Illumination Filtering</strong> Holger Dammertz, Daniel Sewtz, Johannes Hanika and Hendrik P.A. LenschHigh Performance Graphics 2010</a></p></li><li><p><a target="_blank" rel="noopener" href="http://kaiminghe.com/publications/pami12guidedfilter.pdf">[He et al. 2012] <strong>Guided Image Filtering</strong> Kaiming He, Jian Sun and Xiaoou Tang2012</a></p></li><li><p><a target="_blank" rel="noopener" href="https://cs.dartmouth.edu/~wjarosz/publications/mara17towards.html">[Mara et al. 2017] <strong>An Efficient Denoising Algorithm for Global Illumination</strong> Michael Mara, Morgan McGuire, Benedikt Bitterli and Wojciech JaroszACM, High Performance Graphics 2017</a></p></li><li><p><a target="_blank" rel="noopener" href="https://research.nvidia.com/publication/2020-05_Neural-Temporal-Adaptive">[Khademi Kalantari et al. 2013] <strong>Removing the Noise in Monte Carlo Rendering with General Image Denoising Algorithms</strong> Nima Khademi Kalantari and Pradeep SenEurographics 2013</a></p></li><li><p><a target="_blank" rel="noopener" href="http://cvc.ucsb.edu/graphics/Papers/SIGGRAPH2015_LBF/">[Khademi Kalantari et al. 2015] <strong>A Machine Learning Approach for Filtering Monte Carlo Noise</strong> Nima Khademi Kalantari, Pradeep Sen and Steve BakoACM Transactions on Graphics (TOG) 2015</a></p></li><li><p><a target="_blank" rel="noopener" href="https://research.nvidia.com/sites/default/files/publications/dnn_denoise_author.pdf">[R. Alla Chaitanya et al. 2017] <strong>Interactive Reconstruction of Monte Carlo Image Sequences using a Recurrent Denoising Autoencoder</strong> Chakravarty R. Alla Chaitanya, Anton S. Kaplanyan, Christoph Schied, Marco Salvi, Aaron Lefohn, Derek Nowrouzezahrai and Timo AilaACM 2017</a></p></li><li><p><a target="_blank" rel="noopener" href="http://doi.acm.org/10.1145/3197517.3201388">[Vogels et al. 2018] <strong>Denoising with Kernel Prediction and Asymmetric Loss Functions</strong> Thijs Vogels, Fabrice Rousselle, Brian Mcwilliams, Gerhard Rothlin, Alex Harvill, David Adler, Mark Meyer and Jan NovakACM, ACM Transactions on Graphics 2018</a></p></li><li><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1804.02900">[Wang et al. 2018] <strong>A Fully Progressive Approach to Single-Image Super-Resolution</strong> Yifan Wang, Federico Perazzi, Brian McWilliams, Alexander Sorkine-Hornung, Olga Sorkine-Hornung and Christopher SchroersCoRR 2018</a></p></li><li><p><a target="_blank" rel="noopener" href="http://adversarial.mcdenoising.org/">[Xu et al. 2019] <strong>Adversarial Monte Carlo Denoising with Conditioned Auxiliary Feature Modulation</strong> Bing Xu, Junfei Zhang, Rui Wang, Kun Xu, Yong-Liang Yang, Chuan Li and Rui TangACM, ACM Transactions on Graphics 2019</a></p></li><li><p><a target="_blank" rel="noopener" href="https://diglib.eg.org/handle/10.2312/sr20201133">[Meng et al. 2020] <strong>Real-time Monte Carlo Denoising with the Neural Bilateral Grid</strong> Xiaoxu Meng, Quan Zheng, Amitabh Varshney, Gurprit Singh and Matthias ZwickerEurographics 2020</a></p></li><li><p><a target="_blank" rel="noopener" href="https://research.nvidia.com/publication/2020-05_Neural-Temporal-Adaptive">[Hasselgren et al. 2020] <strong>Neural Temporal Adaptive Sampling and Denoising</strong> Jon Hasselgren, Jacob Munkberg, Marco Salvi, Anjul Patney and Aaron LefohnEurographics 2020</a></p></li><li><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1501.00092">[Dong et al. 2015] <strong>Image Super-Resolution Using Deep Convolutional Networks</strong> Chao Dong, Chen Change Loy, Kaiming He and Xiaoou TangCoRR 2015</a></p></li><li><p><a target="_blank" rel="noopener" href="https://research.fb.com/publications/neural-supersampling-for-real-time-rendering/">[Ledig et al. 2016] <strong>Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network</strong> Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew P. Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang and Wenzhe ShiCoRR 2016</a></p></li><li><p><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/800059.801168">[Korein et al. 1983] <strong>Temporal Anti-Aliasing in Computer Generated Animation</strong> Jonathan Korein and Norman BadlerACM 1983</a></p></li><li><p><a target="_blank" rel="noopener" href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14018">[Yang et al. 2020] <strong>A Survey of Temporal Antialiasing Techniques</strong> Lei Yang, Shiqiu Liu and Marco SalviComputer Graphics Forum 2020</a></p></li><li><p><a target="_blank" rel="noopener" href="http://research.nvidia.com/publication/2017-07_Spatiotemporal-Variance-Guided-Filtering%3A">[Mara et al. 2017] <strong>Spatiotemporal Variance-Guided Filtering</strong> Christoph Schied2017</a></p></li><li><p><a target="_blank" rel="noopener" href="http://toomuchvoltage.com/pub/vbhptwstd/abstract.pdf">[Schied 2017] <strong>Voxel Based Hybrid Path Tracing with Spatial Denoising</strong> Baktash Abdollah-shamshir-sazi3D 2018</a></p></li><li><p><a target="_blank" rel="noopener" href="https://cg.ivd.kit.edu/atf.php">[Abdollah-shamshir-saz 2018] <strong>Gradient Estimation for Real-Time Adaptive Temporal Filtering</strong> Christoph Schied2018</a></p></li><li><p><a target="_blank" rel="noopener" href="http://www.tut.fi/vga/publications/Blockwise_Multi-Order_Feature_Regression_for_Real-Time_Path_Tracing_Reconstruction.html">[Schied 2018] <strong>Blockwise Multi-Order Feature Regression for Real-Time Path Tracing Reconstruction</strong> Matias Koskela and Kalle ImmonenACM Transactions on Graphics (TOG) 2019</a></p></li><li><p><a target="_blank" rel="noopener" href="https://auzaiffe.files.wordpress.com/2019/05/digital-dragons-leveraging-ray-tracing-hardware-acceleration-in-unity.pdf">[Koskela et al. 2019] <strong>Leveraging Ray Tracing Hardware Acceleration In Unity</strong> Anis BenyoubDigital Dragons 2019</a></p></li><li><p><a target="_blank" rel="noopener" href="http://www.realtimerendering.com/raytracinggems/">[Benyoub 2019] <strong>Cinematic Rendering in UE4 with Real-Time Ray Tracing and Denoising</strong> Edward Liu, Ignacio Llamas, Juan Cañada and Patrick KellyRay Tracing Gems 2019</a></p></li><li><p><a target="_blank" rel="noopener" href="http://graphics.stanford.edu/papers/veach_thesis/">[Liu et al. 2019] <strong>Robust Monte Carlo Methods for Light Transport Simulation</strong> Eric VeachStanford University 1998</a></p></li><li><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2005.07547.pdf">[Veach 1998] <strong>Online Path Sampling Control with Progressive Spatio-Temporal Filtering</strong> Jacopo PantaleoniNVIDIA 2020</a></p></li><li><p><a target="_blank" rel="noopener" href="https://research.nvidia.com/publication/2020-07_Spatiotemporal-reservoir-resampling">[Pantaleoni 2020] <strong>Spatiotemporal Reservoir Resampling for Real-Time Ray Tracing With Dynamic Direct Lighting</strong> Benedikt Bitterli, Chris Wyman, Matt Pharr, Peter Shirley, Aaron Lefohn and Wojciech JaroszACM Transaction on Graphics 2020</a></p></li><li><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2009.10796">[Bitterli et al. 2020] <strong>Scaling Probe-Based Real-Time Dynamic Global Illumination for Production</strong> Zander Majercik, Adam Marrs, Josef Spjut and Morgan McGuirearXiv 2020</a></p></li><li><p><a target="_blank" rel="noopener" href="http://www.jp.square-enix.com/tech/library/pdf/Specular%20Lobe-Aware%20Filtering%20and%20Upsampling%20for%20Interactive%20Indirect%20Illumination.pdf">[Majercik et al. 2020] <strong>Specular Lobe-Aware Filtering and Upsampling for Interactive Indirect Illumination</strong> Yusuke TokuyoshiEurographics 2015</a></p></li></ul></div><div class="popular-posts-header">Related Posts</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="/archives/7dbe30e4.html" rel="bookmark">Blockwise Multi-Order Feature Regression for Real-Time Path Tracing Reconstruction</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/archives/971404c0.html" rel="bookmark">Rendering Course by Wangningbei</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/archives/8b6729fe.html" rel="bookmark">A Gentle Introduction to DirectX Raytracing 14</a></div></li></ul><footer class="post-footer"><div class="post-tags"><a href="/tags/Computer-Graphics/" rel="tag"># Computer Graphics</a> <a href="/tags/Ray-Tracing/" rel="tag"># Ray Tracing</a></div><div class="post-nav"><div class="post-nav-item"><a href="/archives/d2c56b54.html" rel="prev" title="侯捷的职业建议"><i class="fa fa-chevron-left"></i> 侯捷的职业建议</a></div><div class="post-nav-item"><a href="/archives/17b5358a.html" rel="next" title="C4编译器复现：CmmCompiler">C4编译器复现：CmmCompiler <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><script>window.addEventListener("tabs:register",()=>{let{activeClass:e}=CONFIG.comments;if(CONFIG.comments.storage&&(e=localStorage.getItem("comments_active")||e),e){let t=document.querySelector(`a[href="#comment-${e}"]`);t&&t.click()}}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">Table of Contents</li><li class="sidebar-nav-overview">Overview</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%95%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">引言</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Prior-Art"><span class="nav-number">2.</span> <span class="nav-text">Prior Art</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sampling"><span class="nav-number">3.</span> <span class="nav-text">Sampling</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#SVGF"><span class="nav-number">3.1.</span> <span class="nav-text">SVGF</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#A-SVGF"><span class="nav-number">3.2.</span> <span class="nav-text">A-SVGF</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ReSTIR"><span class="nav-number">3.3.</span> <span class="nav-text">ReSTIR</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Machine-Learning"><span class="nav-number">4.</span> <span class="nav-text">Machine Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#OIDN"><span class="nav-number">4.1.</span> <span class="nav-text">OIDN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Optix"><span class="nav-number">4.2.</span> <span class="nav-text">Optix</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DLSS"><span class="nav-number">4.3.</span> <span class="nav-text">DLSS</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Denoiser-Design"><span class="nav-number">5.</span> <span class="nav-text">Denoiser Design</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Prepass"><span class="nav-number">5.1.</span> <span class="nav-text">Prepass</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Accumulation"><span class="nav-number">5.2.</span> <span class="nav-text">Accumulation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Statistical-Analysis"><span class="nav-number">5.3.</span> <span class="nav-text">Statistical Analysis</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Filtering"><span class="nav-number">5.4.</span> <span class="nav-text">Filtering</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Limitations"><span class="nav-number">5.5.</span> <span class="nav-text">Limitations</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#References"><span class="nav-number">6.</span> <span class="nav-text">References</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Yousazoe" src="https://img.yousazoe.top/uPic/img/blog/icon/icon.jpeg"><p class="site-author-name" itemprop="name">Yousazoe</p><div class="site-description" itemprop="description">done is better than perfect</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">298</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">47</span> <span class="site-state-item-name">categories</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">72</span> <span class="site-state-item-name">tags</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="mailto:zoeyousa@gmail.com" title="E-Mail → mailto:zoeyousa@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i></a> </span><span class="links-of-author-item"><a href="https://github.com/Yousazoe" title="GitHub → https://github.com/Yousazoe" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a> </span><span class="links-of-author-item"><a href="https://twitter.com/YousaZoe" title="Twitter → https://twitter.com/YousaZoe" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i></a> </span><span class="links-of-author-item"><a href="https://steamcommunity.com/profiles/76561198856466228/" title="Steam → https://steamcommunity.com/profiles/76561198856466228/" rel="noopener" target="_blank"><i class="fab fa-steam fa-fw"></i></a> </span><span class="links-of-author-item"><a href="https://www.chess.com/member/yousazoe" title="Chess → https://www.chess.com/member/yousazoe" rel="noopener" target="_blank"><i class="fa fa-chess-pawn fa-fw"></i></a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/399504060" title="Bilibili → https://space.bilibili.com/399504060" rel="noopener" target="_blank"><i class="fa fa-th-large fa-fw"></i></a> </span><span class="links-of-author-item"><a href="/atom.xml" title="RSS → /atom.xml"><i class="fa fa-rss fa-fw"></i></a></span></div><div class="cc-license motion-element" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div></div><div class="twopeople"><div class="container" style="height:200px"><canvas class="illo" width="800" height="800" style="max-width:200px;max-height:200px;touch-action:none;width:640px;height:640px"></canvas></div><script src="https://img.yousazoe.top/js/twopeople1.js"></script><script src="https://img.yousazoe.top/js/zdog.dist.js"></script><script id="rendered-js" src="https://img.yousazoe.top/js/twopeople.js"></script><style>.twopeople{margin:0;align-items:center;justify-content:center;text-align:center}canvas{display:block;margin:0 auto;cursor:move}</style></div><div class="cc-license animated" itemprop="sponsor"><link rel="preconnect" href="https://www.netlify.com"><span class="exturl cc-opacity" title="Deploy with Netlify → https://www.netlify.com" data-url="aHR0cHM6Ly93d3cubmV0bGlmeS5jb20="><img width="80" src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="https://www.netlify.com/img/global/badges/netlify-dark.svg" alt="Netlify"></span></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="translate-style">繁/简：<a id="translateLink" href="javascript:translatePage();">繁体</a></div><script type="text/javascript" src="/js/tw_cn.js"></script><script type="text/javascript">var defaultEncoding=2,translateDelay=0,cookieDomain="https://tding.top/",msgToTraditionalChinese="繁体",msgToSimplifiedChinese="简体",translateButtonId="translateLink";translateInitilization()</script><div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">晋ICP备2021009930号 </a><img src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="https://img.yousazoe.top/uPic/img/blog/icon/beian.png" style="display:inline-block"></div><div class="copyright">© 2020 – <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Yousazoe</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="Symbols count total">4.5m</span></div><div class="powered-by"><span><a target="_blank" rel="noopener" href="https://www.upyun.com/?utm_source=lianmeng&amp;utm_medium=referral"><img src="https://img.yousazoe.top/uPic/img/blog/icon/mona-loading-default.gif" data-original="https://cdn.jsdelivr.net/gh/YukiNoUta/cdn-static@main/blog/svg/upyun.svg" width="53" height="18" style="fill:currentColor;display:inline-block"></a></span><span class="post-meta-divider">|</span>今早雾霾蔽日，但是不要害怕，太阳依旧在云端</div><div class="busuanzi-count"><script data-pjax="" async="" src="js/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:inline"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="Total Visitors"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-divider">|</span> <span class="post-meta-item" id="busuanzi_container_site_pv" style="display:inline"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="Total Views"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="//unpkg.com/animejs@3.1.0/lib/anime.min.js"></script><script src="//npm.elemecdn.com/pjax/pjax.min.js"></script><script src="//lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js"></script><script src="//unpkg.com/lozad@1.16.0/dist/lozad.min.js"></script><script src="//lib.baomitu.com/pangu/4.0.7/pangu.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
    $(document).ready(function () {

    if(location.href.indexOf("#reloaded")==-1){
        location.href=location.href+"#reloaded";
        location.reload();
    }
}）
#在这后面可以加入程序的其他代码  


  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });

  
  NexT.boot.refresh();
  
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  
  NexT.utils.updateSidebarPosition();
});</script><script defer="" src="//img.yousazoe.top/js/three.min.js"></script><script defer="" src="//img.yousazoe.top/js/caidai.js"></script><script data-pjax="">!function(){var e,t,o,n,r=document.getElementsByTagName("link");if(0<r.length)for(i=0;i<r.length;i++)"canonical"==r[i].rel.toLowerCase()&&r[i].href&&(e=r[i].href);t=(e||window.location.protocol).split(":")[0],e=e||window.location.href,window,o=e,n=document.referrer,/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(o)||(t="https"===String(t).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif",n?(t+="?r="+encodeURIComponent(document.referrer),o&&(t+="&l="+o)):o&&(t+="?l="+o),(new Image).src=t)}()</script><script src="/js/local-search.js"></script><script data-pjax="">document.querySelectorAll(".pdfobject-container").forEach(e=>{var t=e.dataset.target,a="#"+Object.entries({navpanes:0,toolbar:0,statusbar:0,pagemode:"thumbs",view:"FitH"}).map(([e,t])=>`${e}=${encodeURIComponent(t)}`).join("&"),r=`/lib/pdf/web/viewer.html?file=${encodeURIComponent(t)}${a}`;NexT.utils.supportsPDFs()?e.innerHTML=`<embed class="pdfobject" src="${t+a}" type="application/pdf" style="height: ${e.dataset.height};">`:e.innerHTML=`<iframe src="${r}" style="height: ${e.dataset.height};" frameborder="0"></iframe>`})</script><script data-pjax="">document.querySelectorAll("pre.mermaid").length&&NexT.utils.getScript("//lib.baomitu.com/mermaid/8.4.8/mermaid.min.js",()=>{mermaid.initialize({theme:"forest",logLevel:3,flowchart:{curve:"linear"},gantt:{axisFormat:"%m/%d/%Y"},sequence:{actorMargin:50}})},window.mermaid)</script><div id="pjax"></div><script type="text/javascript" src="/js/cursor/fireworks.js"></script><script src="https://img.yousazoe.top/live2dw/lib/L2Dwidget.min.js"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,model:{jsonPath:"/live2dw/assets/assets/hijiki.model.json"},display:{position:"right",width:100,height:200},mobile:{show:!0},log:!1})</script><script>window.imageLazyLoadSetting={isSPA:!1,preloadRatio:5,processImages:null}</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})})</script><script>!function(n){n.imageLazyLoadSetting.processImages=o;var e=n.imageLazyLoadSetting.isSPA,i=n.imageLazyLoadSetting.preloadRatio||1,r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function o(){e&&(r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")));for(var t,a=0;a<r.length;a++)0<=(t=(t=r[a]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(n.innerHeight*i||document.documentElement.clientHeight*i)&&function(){var e=r[a],t=e,n=function(){r=r.filter(function(t){return e!==t})},i=new Image,o=t.getAttribute("data-original");i.onload=function(){t.src=o,n()},t.src!==o&&(i.src=o)}()}o(),n.addEventListener("scroll",function(){var t=o,e=n;clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(e)},500)})}(this)</script><script type="text/javascript" charset="utf-8" src="/js/lazyload-plugin/lazyload.intersectionObserver.min.js"></script></body></html>